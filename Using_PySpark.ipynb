{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import  col, count, sum, avg, to_timestamp, date_format, monotonically_increasing_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MySparkApp\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+---------+------------+-------+--------+\n",
      "|      Date|    Hour|StoreNo|StoreName|EntranceName|InCount|OutCount|\n",
      "+----------+--------+-------+---------+------------+-------+--------+\n",
      "|2021-12-11|00:00:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|00:00:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|00:00:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|00:00:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|00:15:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|00:15:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|00:15:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|00:15:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|00:30:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|00:30:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|00:30:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|00:30:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|00:45:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|00:45:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|00:45:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|00:45:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|01:00:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|01:00:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|01:00:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|01:00:00|     30| My_Store|         004|      0|       0|\n",
      "+----------+--------+-------+---------+------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('Store_Sensors_data.csv', header=True, inferSchema=True)\n",
    "df = df.withColumn('Hour', date_format(col('hour'), \"HH:mm:ss\"))\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|      Date|    Hour|\n",
      "+----------+--------+\n",
      "|2021-12-11|00:00:00|\n",
      "|2021-12-11|00:00:00|\n",
      "|2021-12-11|00:00:00|\n",
      "|2021-12-11|00:00:00|\n",
      "|2021-12-11|00:15:00|\n",
      "|2021-12-11|00:15:00|\n",
      "|2021-12-11|00:15:00|\n",
      "|2021-12-11|00:15:00|\n",
      "|2021-12-11|00:30:00|\n",
      "|2021-12-11|00:30:00|\n",
      "|2021-12-11|00:30:00|\n",
      "|2021-12-11|00:30:00|\n",
      "|2021-12-11|00:45:00|\n",
      "|2021-12-11|00:45:00|\n",
      "|2021-12-11|00:45:00|\n",
      "|2021-12-11|00:45:00|\n",
      "|2021-12-11|01:00:00|\n",
      "|2021-12-11|01:00:00|\n",
      "|2021-12-11|01:00:00|\n",
      "|2021-12-11|01:00:00|\n",
      "+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Date', 'Hour').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Hour: string (nullable = true)\n",
      " |-- StoreNo: integer (nullable = true)\n",
      " |-- StoreName: string (nullable = true)\n",
      " |-- EntranceName: string (nullable = true)\n",
      " |-- InCount: integer (nullable = true)\n",
      " |-- OutCount: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Infering the Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------+---------+------------+-------+--------+\n",
      "|      Date|  Hour|StoreNo|StoreName|EntranceName|InCount|OutCount|\n",
      "+----------+------+-------+---------+------------+-------+--------+\n",
      "|2021-12-11| 0:0:0|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11| 0:0:0|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11| 0:0:0|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11| 0:0:0|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|0:15:0|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|0:15:0|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|0:15:0|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|0:15:0|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|0:30:0|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|0:30:0|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|0:30:0|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|0:30:0|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|0:45:0|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|0:45:0|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|0:45:0|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|0:45:0|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11| 1:0:0|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11| 1:0:0|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11| 1:0:0|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11| 1:0:0|     30| My_Store|         004|      0|       0|\n",
      "+----------+------+-------+---------+------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff = spark.read.csv('Store_Sensors_data.csv', header=True)\n",
    "dff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Hour: string (nullable = true)\n",
      " |-- StoreNo: string (nullable = true)\n",
      " |-- StoreName: string (nullable = true)\n",
      " |-- EntranceName: string (nullable = true)\n",
      " |-- InCount: string (nullable = true)\n",
      " |-- OutCount: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff = dff.withColumn('Hour', col('Hour').cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns and their new types\n",
    "columnMapping = {\n",
    "    'Date': 'date',\n",
    "    'Hour': 'timestamp',\n",
    "    'StoreName': 'string',\n",
    "    'StoreNo' : 'integer'\n",
    ",    'EntranceName': 'string',\n",
    "    'InCount': 'integer',\n",
    "    'OutCount': 'integer'\n",
    "}\n",
    "\n",
    "# Change the types of multiple columns\n",
    "for column, new_type in columnMapping.items():\n",
    "    dff = dff.withColumn(column, col(column).cast(new_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Hour: timestamp (nullable = true)\n",
      " |-- StoreNo: integer (nullable = true)\n",
      " |-- StoreName: string (nullable = true)\n",
      " |-- EntranceName: string (nullable = true)\n",
      " |-- InCount: integer (nullable = true)\n",
      " |-- OutCount: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow copy problem does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------+---------+------------+-------+--------+\n",
      "|      Date|               Hour|StoreNo|StoreName|EntranceName|InCount|OutCount|\n",
      "+----------+-------------------+-------+---------+------------+-------+--------+\n",
      "|2021-12-11|2023-07-05 00:00:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:00:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:00:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:00:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:15:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:15:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:15:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:15:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:30:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:30:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:30:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:30:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:45:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:45:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:45:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:45:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|2023-07-05 01:00:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|2023-07-05 01:00:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|2023-07-05 01:00:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|2023-07-05 01:00:00|     30| My_Store|         004|      0|       0|\n",
      "+----------+-------------------+-------+---------+------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dff.withColumnRenamed('Hour', 'ZZZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------+---------+------------+-------+--------+\n",
      "|      Date|                ZZZ|StoreNo|StoreName|EntranceName|InCount|OutCount|\n",
      "+----------+-------------------+-------+---------+------------+-------+--------+\n",
      "|2021-12-11|2023-07-05 00:00:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:00:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:00:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:00:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:15:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:15:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:15:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:15:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:30:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:30:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:30:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:30:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:45:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:45:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:45:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:45:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|2023-07-05 01:00:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|2023-07-05 01:00:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|2023-07-05 01:00:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|2023-07-05 01:00:00|     30| My_Store|         004|      0|       0|\n",
      "+----------+-------------------+-------+---------+------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------+---------+------------+-------+--------+\n",
      "|      Date|               Hour|StoreNo|StoreName|EntranceName|InCount|OutCount|\n",
      "+----------+-------------------+-------+---------+------------+-------+--------+\n",
      "|2021-12-11|2023-07-05 00:00:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:00:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:00:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:00:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:15:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:15:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:15:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:15:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:30:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:30:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:30:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:30:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:45:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:45:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:45:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|2023-07-05 00:45:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|2023-07-05 01:00:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|2023-07-05 01:00:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|2023-07-05 01:00:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|2023-07-05 01:00:00|     30| My_Store|         004|      0|       0|\n",
      "+----------+-------------------+-------+---------+------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Hour: string (nullable = true)\n",
      " |-- StoreNo: integer (nullable = true)\n",
      " |-- StoreName: string (nullable = true)\n",
      " |-- EntranceName: string (nullable = true)\n",
      " |-- InCount: integer (nullable = true)\n",
      " |-- OutCount: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dim Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+---------+------------+-------+--------+\n",
      "|      Date|    Hour|StoreNo|StoreName|EntranceName|InCount|OutCount|\n",
      "+----------+--------+-------+---------+------------+-------+--------+\n",
      "|2021-12-11|00:00:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|00:00:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|00:00:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|00:00:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|00:15:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|00:15:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|00:15:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|00:15:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|00:30:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|00:30:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|00:30:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|00:30:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|00:45:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|00:45:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|00:45:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|00:45:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|01:00:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|01:00:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|01:00:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|01:00:00|     30| My_Store|         004|      0|       0|\n",
      "+----------+--------+-------+---------+------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2652"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_store = df.select(['StoreNo', 'StoreName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_store = my_store.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+\n",
      "|StoreNo|       StoreName|\n",
      "+-------+----------------+\n",
      "|     34|     Their_Store|\n",
      "|     31|       Our_Store|\n",
      "|     36| Their_Our_Store|\n",
      "|     38|  Their_My_Store|\n",
      "|     32|      Your_Store|\n",
      "|     35|mine_Their_Store|\n",
      "|     30|        My_Store|\n",
      "+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_store.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_store = my_store.withColumn(\"StoreID\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_store = my_store.select(\"StoreID\", \"StoreName\", \"StoreNo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+-------+\n",
      "|StoreID|       StoreName|StoreNo|\n",
      "+-------+----------------+-------+\n",
      "|      0|     Their_Store|     34|\n",
      "|      1|       Our_Store|     31|\n",
      "|      2| Their_Our_Store|     36|\n",
      "|      3|  Their_My_Store|     38|\n",
      "|      4|      Your_Store|     32|\n",
      "|      5|mine_Their_Store|     35|\n",
      "|      6|        My_Store|     30|\n",
      "+-------+----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_store.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my_sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sensor = df.select(['StoreNo', 'EntranceName']).dropDuplicates().sort('StoreNo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|StoreNo| EntranceName|\n",
      "+-------+-------------+\n",
      "|     30|          004|\n",
      "|     30|          002|\n",
      "|     30|          001|\n",
      "|     30|          003|\n",
      "|     31|Main Entrance|\n",
      "|     32|         Main|\n",
      "|     34|         Main|\n",
      "|     35|         Main|\n",
      "|     36|         Main|\n",
      "|     38|         Main|\n",
      "+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_sensor.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-------+----------------+\n",
      "|StoreNo| EntranceName|StoreID|       StoreName|\n",
      "+-------+-------------+-------+----------------+\n",
      "|     34|         Main|      0|     Their_Store|\n",
      "|     31|Main Entrance|      1|       Our_Store|\n",
      "|     36|         Main|      2| Their_Our_Store|\n",
      "|     38|         Main|      3|  Their_My_Store|\n",
      "|     32|         Main|      4|      Your_Store|\n",
      "|     35|         Main|      5|mine_Their_Store|\n",
      "|     30|          003|      6|        My_Store|\n",
      "|     30|          001|      6|        My_Store|\n",
      "|     30|          002|      6|        My_Store|\n",
      "|     30|          004|      6|        My_Store|\n",
      "+-------+-------------+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_sensor = my_sensor.join(my_store, how='inner', on='StoreNo')\n",
    "my_sensor.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sensor = my_sensor.withColumn(\"SensorID\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-------+----------------+--------+\n",
      "|StoreNo| EntranceName|StoreID|       StoreName|SensorID|\n",
      "+-------+-------------+-------+----------------+--------+\n",
      "|     34|         Main|      0|     Their_Store|       0|\n",
      "|     31|Main Entrance|      1|       Our_Store|       1|\n",
      "|     36|         Main|      2| Their_Our_Store|       2|\n",
      "|     38|         Main|      3|  Their_My_Store|       3|\n",
      "|     32|         Main|      4|      Your_Store|       4|\n",
      "|     35|         Main|      5|mine_Their_Store|       5|\n",
      "|     30|          003|      6|        My_Store|       6|\n",
      "|     30|          001|      6|        My_Store|       7|\n",
      "|     30|          002|      6|        My_Store|       8|\n",
      "|     30|          004|      6|        My_Store|       9|\n",
      "+-------+-------------+-------+----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_sensor.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sensor = my_sensor.select('SensorID', 'StoreID', 'EntranceName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-------------+\n",
      "|SensorID|StoreID| EntranceName|\n",
      "+--------+-------+-------------+\n",
      "|       0|      0|         Main|\n",
      "|       1|      1|Main Entrance|\n",
      "|       2|      2|         Main|\n",
      "|       3|      3|         Main|\n",
      "|       4|      4|         Main|\n",
      "|       5|      5|         Main|\n",
      "|       6|      6|          003|\n",
      "|       7|      6|          001|\n",
      "|       8|      6|          002|\n",
      "|       9|      6|          004|\n",
      "+--------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_sensor.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dim_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dim_date_df(start_date: str, end_date: str, upsert_dataframe: pyspark.sql.dataframe.DataFrame = None) -> pyspark.sql.dataframe.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a dimension date data frame with date-related information between the specified start and end dates.\n",
    "\n",
    "    Args:\n",
    "        start_date (str): The start date in the format 'YYYY-MM-DD'.\n",
    "        end_date (str): The end date in the format 'YYYY-MM-DD'.\n",
    "        upsert_dataframe (pd.DataFrame, optional): An existing dataframe to perform an upsert (update or insert) operation. \n",
    "                                                   If provided, new dates will be appended to the dataframe based on the 'Date_Key' column.\n",
    "                                                   Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The generated dimension table with the following columns:\n",
    "\n",
    "        - Date_Key: A unique key representing the date in the format 'YYYYMMDD'.\n",
    "        - Full_Date: The full date in the format 'YYYY-MM-DD'.\n",
    "        - Day_of_Week: The day of the week as an integer (1 for Monday, 2 for Tuesday, etc.).\n",
    "        - Day_of_Month: The day of the month as an integer.\n",
    "        - Day_of_Year: The day of the year as an integer.\n",
    "        - Day_Name: The name of the day of the week.\n",
    "        - Week_of_month: The week of the month as an integer.\n",
    "        - Week_of_year: The week of the year as an integer.\n",
    "        - Month_Of_year: The month of the year as an integer.\n",
    "        - Days_in_Month: The number of days in the month.\n",
    "        - Month_Name: The name of the month.\n",
    "        - Year: The year as an integer.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: Raised if the 'Date_Key' column is not present in the upsert_dataframe when performing an upsert operation.\n",
    "    \"\"\"\n",
    "    dim_date_dict = {\n",
    "        'Date_Key': [],\n",
    "        'Full_Date': [],\n",
    "        'Day_of_Week': [],\n",
    "        'Day_of_Month': [],\n",
    "        'Day_of_Year': [],\n",
    "        'Day_Name': [],\n",
    "        'Week_of_month': [],\n",
    "        'Week_of_year': [],\n",
    "        'Month_Of_year': [],\n",
    "        'Days_in_Month': [],\n",
    "        'Month_Name': [],\n",
    "        'Year': []\n",
    "    }\n",
    "\n",
    "    for date_ in pd.date_range(start_date, end_date):\n",
    "        full_date = str(date_)[:-9].strip()\n",
    "        date_key = int(full_date.replace('-', ''))\n",
    "\n",
    "        if upsert_dataframe is not None:\n",
    "            if 'Date_Key' not in upsert_dataframe.columns:\n",
    "                raise KeyError(\"No 'Date_Key' column found in the upsert dataframe.\")\n",
    "            if upsert_dataframe.filter(col('Date_Key').isin(date_key)).count() > 0:\n",
    "                continue\n",
    "\n",
    "        dim_date_dict['Date_Key'].append(date_key)\n",
    "        dim_date_dict['Full_Date'].append(full_date)\n",
    "        dim_date_dict['Day_of_Week'].append(date_.day_of_week + 1)\n",
    "        dim_date_dict['Day_of_Month'].append(date_.day)\n",
    "        dim_date_dict['Day_of_Year'].append(date_.day_of_year)\n",
    "        dim_date_dict['Day_Name'].append(date_.day_name())\n",
    "        dim_date_dict['Week_of_month'].append(date_.weekday() + 1)\n",
    "        dim_date_dict['Week_of_year'].append(date_.weekofyear)\n",
    "        dim_date_dict['Month_Of_year'].append(date_.month)\n",
    "        dim_date_dict['Days_in_Month'].append(date_.days_in_month)\n",
    "        dim_date_dict['Month_Name'].append(date_.month_name())\n",
    "        dim_date_dict['Year'].append(date_.year)\n",
    "    if len(dim_date_dict['Date_Key']) > 0:\n",
    "        df = spark.createDataFrame(pd.DataFrame(dim_date_dict))\n",
    "        if upsert_dataframe is not None:\n",
    "            df = upsert_dataframe.union(df)\n",
    "    else:\n",
    "        df = upsert_dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+------------+-----------+---------+-------------+------------+-------------+-------------+----------+----+\n",
      "|Date_Key| Full_Date|Day_of_Week|Day_of_Month|Day_of_Year| Day_Name|Week_of_month|Week_of_year|Month_Of_year|Days_in_Month|Month_Name|Year|\n",
      "+--------+----------+-----------+------------+-----------+---------+-------------+------------+-------------+-------------+----------+----+\n",
      "|20200101|2020-01-01|          3|           1|          1|Wednesday|            3|           1|            1|           31|   January|2020|\n",
      "|20200102|2020-01-02|          4|           2|          2| Thursday|            4|           1|            1|           31|   January|2020|\n",
      "|20200103|2020-01-03|          5|           3|          3|   Friday|            5|           1|            1|           31|   January|2020|\n",
      "|20200104|2020-01-04|          6|           4|          4| Saturday|            6|           1|            1|           31|   January|2020|\n",
      "|20200105|2020-01-05|          7|           5|          5|   Sunday|            7|           1|            1|           31|   January|2020|\n",
      "+--------+----------+-----------+------------+-----------+---------+-------------+------------+-------------+-------------+----------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dim_date = get_dim_date_df('2020-01-01', '2020-01-05')\n",
    "dim_date.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+------------+-----------+---------+-------------+------------+-------------+-------------+----------+----+\n",
      "|Date_Key| Full_Date|Day_of_Week|Day_of_Month|Day_of_Year| Day_Name|Week_of_month|Week_of_year|Month_Of_year|Days_in_Month|Month_Name|Year|\n",
      "+--------+----------+-----------+------------+-----------+---------+-------------+------------+-------------+-------------+----------+----+\n",
      "|20200101|2020-01-01|          3|           1|          1|Wednesday|            3|           1|            1|           31|   January|2020|\n",
      "|20200102|2020-01-02|          4|           2|          2| Thursday|            4|           1|            1|           31|   January|2020|\n",
      "|20200103|2020-01-03|          5|           3|          3|   Friday|            5|           1|            1|           31|   January|2020|\n",
      "|20200104|2020-01-04|          6|           4|          4| Saturday|            6|           1|            1|           31|   January|2020|\n",
      "|20200105|2020-01-05|          7|           5|          5|   Sunday|            7|           1|            1|           31|   January|2020|\n",
      "|20200106|2020-01-06|          1|           6|          6|   Monday|            1|           2|            1|           31|   January|2020|\n",
      "+--------+----------+-----------+------------+-----------+---------+-------------+------------+-------------+-------------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_date = get_dim_date_df('2020-01-01', '2020-01-06', dim_date)\n",
    "dim_date.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dim_time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Have to create pd df first and then convert to spark df beacuse of hustle:\n",
    "\n",
    "`TypeError: Can not infer schema for type:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dim_time_df(frequency: str = 'H') -> pyspark.sql.dataframe.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a pandas DataFrame with start and end times based on a specified frequency.\n",
    "\n",
    "    Args:\n",
    "        frequency (str): Frequency of the time intervals. Defaults to 'H' (hourly).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns 'StartTime' and 'EndTime'.\n",
    "\n",
    "    \"\"\"\n",
    "    startTime = []\n",
    "    timekey = []\n",
    "    for date_ in pd.date_range(start='2023-01-01', end='2023-01-02', freq=frequency):\n",
    "        time = date_.time()\n",
    "        startTime.append(str(time))\n",
    "        timekey.append(int(str(time).replace(':', '')))\n",
    "    startTime = startTime[:-1]\n",
    "    timekey = timekey[:-1]\n",
    "    endTime = startTime[1:] + startTime[0:1]\n",
    "\n",
    "    # return spark.createDataFrame(pd.DataFrame({'Time_Key':timekey,'Start_Time': startTime, 'End_Time': endTime}))\n",
    "    res = spark.createDataFrame(pd.DataFrame({'Time_Key':timekey,'Start_Time': startTime, 'End_Time': endTime}))\n",
    "\n",
    "    # res = res.withColumn('Start_Time', date_format(col('Start_Time'), format=\"HH:mm:ss\"))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+\n",
      "|Time_Key|Start_Time|End_Time|\n",
      "+--------+----------+--------+\n",
      "|       0|  00:00:00|00:01:40|\n",
      "|     140|  00:01:40|00:03:20|\n",
      "|     320|  00:03:20|00:05:00|\n",
      "|     500|  00:05:00|00:06:40|\n",
      "|     640|  00:06:40|00:08:20|\n",
      "|     820|  00:08:20|00:10:00|\n",
      "|    1000|  00:10:00|00:11:40|\n",
      "|    1140|  00:11:40|00:13:20|\n",
      "|    1320|  00:13:20|00:15:00|\n",
      "|    1500|  00:15:00|00:16:40|\n",
      "|    1640|  00:16:40|00:18:20|\n",
      "|    1820|  00:18:20|00:20:00|\n",
      "|    2000|  00:20:00|00:21:40|\n",
      "|    2140|  00:21:40|00:23:20|\n",
      "|    2320|  00:23:20|00:25:00|\n",
      "|    2500|  00:25:00|00:26:40|\n",
      "|    2640|  00:26:40|00:28:20|\n",
      "|    2820|  00:28:20|00:30:00|\n",
      "|    3000|  00:30:00|00:31:40|\n",
      "|    3140|  00:31:40|00:33:20|\n",
      "+--------+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = get_dim_time_df('100S')\n",
    "p.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fact Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+---------+------------+-------+--------+\n",
      "|      Date|    Hour|StoreNo|StoreName|EntranceName|InCount|OutCount|\n",
      "+----------+--------+-------+---------+------------+-------+--------+\n",
      "|2021-12-11|00:00:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|00:00:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|00:00:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|00:00:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|00:15:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|00:15:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|00:15:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|00:15:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|00:30:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|00:30:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|00:30:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|00:30:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|00:45:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|00:45:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|00:45:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|00:45:00|     30| My_Store|         004|      0|       0|\n",
      "|2021-12-11|01:00:00|     30| My_Store|         001|      0|       0|\n",
      "|2021-12-11|01:00:00|     30| My_Store|         002|      0|       0|\n",
      "|2021-12-11|01:00:00|     30| My_Store|         003|      0|       0|\n",
      "|2021-12-11|01:00:00|     30| My_Store|         004|      0|       0|\n",
      "+----------+--------+-------+---------+------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2652"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_date = get_dim_date_df('2019-01-01', '2025-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+------------+-----------+---------+-------------+------------+-------------+-------------+----------+----+\n",
      "|Date_Key| Full_Date|Day_of_Week|Day_of_Month|Day_of_Year| Day_Name|Week_of_month|Week_of_year|Month_Of_year|Days_in_Month|Month_Name|Year|\n",
      "+--------+----------+-----------+------------+-----------+---------+-------------+------------+-------------+-------------+----------+----+\n",
      "|20190101|2019-01-01|          2|           1|          1|  Tuesday|            2|           1|            1|           31|   January|2019|\n",
      "|20190102|2019-01-02|          3|           2|          2|Wednesday|            3|           1|            1|           31|   January|2019|\n",
      "|20190103|2019-01-03|          4|           3|          3| Thursday|            4|           1|            1|           31|   January|2019|\n",
      "|20190104|2019-01-04|          5|           4|          4|   Friday|            5|           1|            1|           31|   January|2019|\n",
      "|20190105|2019-01-05|          6|           5|          5| Saturday|            6|           1|            1|           31|   January|2019|\n",
      "+--------+----------+-----------+------------+-----------+---------+-------------+------------+-------------+-------------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_date.limit(5).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completing look ups for `date`, `time`, `sensor` and `store` IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+\n",
      "|Time_Key|Start_Time|End_Time|\n",
      "+--------+----------+--------+\n",
      "|       0|  00:00:00|00:15:00|\n",
      "|    1500|  00:15:00|00:30:00|\n",
      "|    3000|  00:30:00|00:45:00|\n",
      "|    4500|  00:45:00|01:00:00|\n",
      "|   10000|  01:00:00|01:15:00|\n",
      "|   11500|  01:15:00|01:30:00|\n",
      "|   13000|  01:30:00|01:45:00|\n",
      "|   14500|  01:45:00|02:00:00|\n",
      "|   20000|  02:00:00|02:15:00|\n",
      "|   21500|  02:15:00|02:30:00|\n",
      "|   23000|  02:30:00|02:45:00|\n",
      "|   24500|  02:45:00|03:00:00|\n",
      "|   30000|  03:00:00|03:15:00|\n",
      "|   31500|  03:15:00|03:30:00|\n",
      "|   33000|  03:30:00|03:45:00|\n",
      "|   34500|  03:45:00|04:00:00|\n",
      "|   40000|  04:00:00|04:15:00|\n",
      "|   41500|  04:15:00|04:30:00|\n",
      "|   43000|  04:30:00|04:45:00|\n",
      "|   44500|  04:45:00|05:00:00|\n",
      "+--------+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- Time_Key: long (nullable = true)\n",
      " |-- Start_Time: string (nullable = true)\n",
      " |-- End_Time: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_quarter_hourly_time = get_dim_time_df('900S')\n",
    "dim_quarter_hourly_time.show()\n",
    "dim_quarter_hourly_time.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `time key` lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(dim_quarter_hourly_time, col('Hour') == col('Start_Time'))\n",
    "df = df.select([\"Date\", 'Time_Key', \"StoreNo\", \"EntranceName\", \"InCount\", \"OutCount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+-------------+-------+--------+\n",
      "|      Date|Time_Key|StoreNo| EntranceName|InCount|OutCount|\n",
      "+----------+--------+-------+-------------+-------+--------+\n",
      "|2021-12-13|       0|     38|         Main|      0|       0|\n",
      "|2021-12-12|       0|     38|         Main|      0|       0|\n",
      "|2021-12-11|       0|     38|         Main|      0|       0|\n",
      "|2021-12-13|       0|     36|         Main|      0|       0|\n",
      "|2021-12-12|       0|     36|         Main|      0|       0|\n",
      "|2021-12-11|       0|     36|         Main|      0|       0|\n",
      "|2021-12-13|       0|     35|         Main|      0|       0|\n",
      "|2021-12-12|       0|     35|         Main|      0|       0|\n",
      "|2021-12-11|       0|     35|         Main|      0|       0|\n",
      "|2021-12-13|       0|     34|         Main|      0|       0|\n",
      "|2021-12-12|       0|     34|         Main|      0|       0|\n",
      "|2021-12-11|       0|     34|         Main|      0|       0|\n",
      "|2021-12-13|       0|     32|         Main|      0|       0|\n",
      "|2021-12-12|       0|     32|         Main|      0|       0|\n",
      "|2021-12-11|       0|     32|         Main|      0|       0|\n",
      "|2021-12-13|       0|     31|Main Entrance|      0|       0|\n",
      "|2021-12-12|       0|     31|Main Entrance|      0|       0|\n",
      "|2021-12-11|       0|     31|Main Entrance|      0|       0|\n",
      "|2021-12-13|       0|     30|          004|      0|       0|\n",
      "|2021-12-13|       0|     30|          003|      0|       0|\n",
      "+----------+--------+-------+-------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `date key` lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(dim_date, col('Date') == col('Full_Date'))\n",
    "df = df.select(['Date_Key', 'Time_Key', \"StoreNo\", \"EntranceName\", \"InCount\", \"OutCount\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+-------------+-------+--------+\n",
      "|Date_Key|Time_Key|StoreNo| EntranceName|InCount|OutCount|\n",
      "+--------+--------+-------+-------------+-------+--------+\n",
      "|20211213|       0|     38|         Main|      0|       0|\n",
      "|20211212|       0|     38|         Main|      0|       0|\n",
      "|20211211|       0|     38|         Main|      0|       0|\n",
      "|20211213|       0|     36|         Main|      0|       0|\n",
      "|20211212|       0|     36|         Main|      0|       0|\n",
      "|20211211|       0|     36|         Main|      0|       0|\n",
      "|20211213|       0|     35|         Main|      0|       0|\n",
      "|20211212|       0|     35|         Main|      0|       0|\n",
      "|20211211|       0|     35|         Main|      0|       0|\n",
      "|20211213|       0|     34|         Main|      0|       0|\n",
      "|20211212|       0|     34|         Main|      0|       0|\n",
      "|20211211|       0|     34|         Main|      0|       0|\n",
      "|20211213|       0|     32|         Main|      0|       0|\n",
      "|20211212|       0|     32|         Main|      0|       0|\n",
      "|20211211|       0|     32|         Main|      0|       0|\n",
      "|20211213|       0|     31|Main Entrance|      0|       0|\n",
      "|20211212|       0|     31|Main Entrance|      0|       0|\n",
      "|20211211|       0|     31|Main Entrance|      0|       0|\n",
      "|20211213|       0|     30|          004|      0|       0|\n",
      "|20211213|       0|     30|          003|      0|       0|\n",
      "+--------+--------+-------+-------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `StoreID` lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(my_store, on=['StoreNo']).select('Date_Key', 'Time_Key', 'StoreID','EntranceName', 'InCount', 'OutCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+-------------+-------+--------+\n",
      "|Date_Key|Time_Key|StoreID| EntranceName|InCount|OutCount|\n",
      "+--------+--------+-------+-------------+-------+--------+\n",
      "|20211212|       0|      3|         Main|      0|       0|\n",
      "|20211212|       0|      2|         Main|      0|       0|\n",
      "|20211212|       0|      5|         Main|      0|       0|\n",
      "|20211212|       0|      0|         Main|      0|       0|\n",
      "|20211212|       0|      4|         Main|      0|       0|\n",
      "|20211212|       0|      1|Main Entrance|      0|       0|\n",
      "|20211212|       0|      6|          004|      0|       0|\n",
      "|20211212|       0|      6|          003|      0|       0|\n",
      "|20211212|       0|      6|          002|      0|       0|\n",
      "|20211212|       0|      6|          001|      0|       0|\n",
      "|20211212|    1500|      3|         Main|      0|       0|\n",
      "|20211212|    1500|      2|         Main|      0|       0|\n",
      "|20211212|    1500|      5|         Main|      0|       0|\n",
      "|20211212|    1500|      0|         Main|      0|       0|\n",
      "|20211212|    1500|      4|         Main|      0|       0|\n",
      "|20211212|    1500|      1|Main Entrance|      0|       0|\n",
      "|20211212|    1500|      6|          004|      0|       0|\n",
      "|20211212|    1500|      6|          003|      0|       0|\n",
      "|20211212|    1500|      6|          002|      0|       0|\n",
      "|20211212|    1500|      6|          001|      0|       0|\n",
      "+--------+--------+-------+-------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Sensor ID` Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(my_sensor, on=['StoreID', 'EntranceName']).select(['Date_Key', 'Time_Key', 'StoreID', 'SensorID', 'InCount', 'OutCount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+--------+-------+--------+\n",
      "|Date_Key|Time_Key|StoreID|SensorID|InCount|OutCount|\n",
      "+--------+--------+-------+--------+-------+--------+\n",
      "|20211213|       0|      0|       1|      0|       0|\n",
      "|20211212|       0|      0|       1|      0|       0|\n",
      "|20211211|       0|      0|       1|      0|       0|\n",
      "|20211213|    1500|      0|       1|      0|       0|\n",
      "|20211212|    1500|      0|       1|      0|       0|\n",
      "|20211211|    1500|      0|       1|      0|       0|\n",
      "|20211213|    3000|      0|       1|      0|       0|\n",
      "|20211212|    3000|      0|       1|      0|       0|\n",
      "|20211211|    3000|      0|       1|      0|       0|\n",
      "|20211213|    4500|      0|       1|      0|       0|\n",
      "|20211212|    4500|      0|       1|      0|       0|\n",
      "|20211211|    4500|      0|       1|      0|       0|\n",
      "|20211213|   10000|      0|       1|      0|       0|\n",
      "|20211212|   10000|      0|       1|      0|       0|\n",
      "|20211211|   10000|      0|       1|      0|       0|\n",
      "|20211213|   11500|      0|       1|      0|       0|\n",
      "|20211212|   11500|      0|       1|      0|       0|\n",
      "|20211211|   11500|      0|       1|      0|       0|\n",
      "|20211213|   13000|      0|       1|      0|       0|\n",
      "|20211212|   13000|      0|       1|      0|       0|\n",
      "+--------+--------+-------+--------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2652"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show()\n",
    "df.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fact Hourly Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+--------+-------+--------+\n",
      "|Date_Key|Time_Key|StoreID|SensorID|InCount|OutCount|\n",
      "+--------+--------+-------+--------+-------+--------+\n",
      "|20211213|       0|      3|       5|      0|       0|\n",
      "|20211212|       0|      3|       5|      0|       0|\n",
      "|20211211|       0|      3|       5|      0|       0|\n",
      "|20211213|       0|      2|       0|      0|       0|\n",
      "|20211212|       0|      2|       0|      0|       0|\n",
      "|20211211|       0|      2|       0|      0|       0|\n",
      "|20211213|       0|      5|       8|      0|       0|\n",
      "|20211212|       0|      5|       8|      0|       0|\n",
      "|20211211|       0|      5|       8|      0|       0|\n",
      "|20211213|       0|      0|       1|      0|       0|\n",
      "|20211212|       0|      0|       1|      0|       0|\n",
      "|20211211|       0|      0|       1|      0|       0|\n",
      "|20211213|       0|      4|       9|      0|       0|\n",
      "|20211212|       0|      4|       9|      0|       0|\n",
      "|20211211|       0|      4|       9|      0|       0|\n",
      "|20211213|       0|      1|       4|      0|       0|\n",
      "|20211212|       0|      1|       4|      0|       0|\n",
      "|20211211|       0|      1|       4|      0|       0|\n",
      "|20211213|       0|      6|       2|      0|       0|\n",
      "|20211213|       0|      6|       7|      0|       0|\n",
      "+--------+--------+-------+--------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2652"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+\n",
      "|Time_Key|Start_Time|End_Time|\n",
      "+--------+----------+--------+\n",
      "|       0|  00:00:00|01:00:00|\n",
      "|   10000|  01:00:00|02:00:00|\n",
      "|   20000|  02:00:00|03:00:00|\n",
      "|   30000|  03:00:00|04:00:00|\n",
      "|   40000|  04:00:00|05:00:00|\n",
      "|   50000|  05:00:00|06:00:00|\n",
      "|   60000|  06:00:00|07:00:00|\n",
      "|   70000|  07:00:00|08:00:00|\n",
      "|   80000|  08:00:00|09:00:00|\n",
      "|   90000|  09:00:00|10:00:00|\n",
      "|  100000|  10:00:00|11:00:00|\n",
      "|  110000|  11:00:00|12:00:00|\n",
      "|  120000|  12:00:00|13:00:00|\n",
      "|  130000|  13:00:00|14:00:00|\n",
      "|  140000|  14:00:00|15:00:00|\n",
      "|  150000|  15:00:00|16:00:00|\n",
      "|  160000|  16:00:00|17:00:00|\n",
      "|  170000|  17:00:00|18:00:00|\n",
      "|  180000|  18:00:00|19:00:00|\n",
      "|  190000|  19:00:00|20:00:00|\n",
      "+--------+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_hourly_data = get_dim_time_df()\n",
    "dim_hourly_data.show()\n",
    "dim_hourly_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2652"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_hourly_data = df\n",
    "fact_hourly_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_hourly_data = fact_hourly_data.withColumn(\n",
    "    'Time_Key', col('Time_Key') - col('Time_Key')%10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+--------+-------+--------+\n",
      "|Date_Key|Time_Key|StoreID|SensorID|InCount|OutCount|\n",
      "+--------+--------+-------+--------+-------+--------+\n",
      "|20211213|       0|      3|       5|      0|       0|\n",
      "|20211212|       0|      3|       5|      0|       0|\n",
      "|20211211|       0|      3|       5|      0|       0|\n",
      "|20211213|       0|      2|       0|      0|       0|\n",
      "|20211212|       0|      2|       0|      0|       0|\n",
      "|20211211|       0|      2|       0|      0|       0|\n",
      "|20211213|       0|      5|       8|      0|       0|\n",
      "|20211212|       0|      5|       8|      0|       0|\n",
      "|20211211|       0|      5|       8|      0|       0|\n",
      "|20211213|       0|      0|       1|      0|       0|\n",
      "|20211212|       0|      0|       1|      0|       0|\n",
      "|20211211|       0|      0|       1|      0|       0|\n",
      "|20211213|       0|      4|       9|      0|       0|\n",
      "|20211212|       0|      4|       9|      0|       0|\n",
      "|20211211|       0|      4|       9|      0|       0|\n",
      "|20211213|       0|      1|       4|      0|       0|\n",
      "|20211212|       0|      1|       4|      0|       0|\n",
      "|20211211|       0|      1|       4|      0|       0|\n",
      "|20211213|       0|      6|       2|      0|       0|\n",
      "|20211213|       0|      6|       7|      0|       0|\n",
      "+--------+--------+-------+--------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2652"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_hourly_data.show()\n",
    "fact_hourly_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+--------+-------+--------+\n",
      "|Date_Key|Time_Key|StoreID|SensorID|InCount|OutCount|\n",
      "+--------+--------+-------+--------+-------+--------+\n",
      "|20211213|   80000|      2|       0|     10|       7|\n",
      "|20211211|  120000|      2|       0|    153|     150|\n",
      "|20211212|   60000|      2|       0|      0|       0|\n",
      "|20211211|   10000|      2|       0|      0|       0|\n",
      "|20211211|   70000|      2|       0|      0|       0|\n",
      "|20211211|       0|      2|       0|      0|       0|\n",
      "|20211211|   60000|      2|       0|      0|       0|\n",
      "|20211213|   20000|      2|       0|      0|       0|\n",
      "|20211212|   80000|      2|       0|      0|       0|\n",
      "|20211212|   20000|      2|       0|      0|       0|\n",
      "|20211213|   60000|      2|       0|      0|       0|\n",
      "|20211212|   30000|      2|       0|      0|       0|\n",
      "|20211211|   80000|      2|       0|      1|       0|\n",
      "|20211211|   40000|      2|       0|      0|       0|\n",
      "|20211212|  100000|      2|       0|    164|     152|\n",
      "|20211212|   40000|      2|       0|      0|       0|\n",
      "|20211212|   90000|      2|       0|      7|       4|\n",
      "|20211211|   50000|      2|       0|      0|       0|\n",
      "|20211211|  100000|      2|       0|    102|      99|\n",
      "|20211213|   40000|      2|       0|      0|       0|\n",
      "+--------+--------+-------+--------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_hourly_data = fact_hourly_data.groupBy(['Date_Key', 'Time_Key', 'StoreID', 'SensorID']).agg(\n",
    "    sum(\"InCount\").alias(\"InCount\"),\n",
    "    sum(\"OutCount\").alias(\"OutCount\")\n",
    "    ).sort(['SensorID'])\n",
    "fact_hourly_data.show()\n",
    "fact_hourly_data.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fact Quarter Hourly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+--------+-------+--------+\n",
      "|Date_Key|Time_Key|StoreID|SensorID|InCount|OutCount|\n",
      "+--------+--------+-------+--------+-------+--------+\n",
      "|20211212|       0|      3|       5|      0|       0|\n",
      "|20211212|       0|      2|       0|      0|       0|\n",
      "|20211212|       0|      5|       8|      0|       0|\n",
      "|20211212|       0|      0|       1|      0|       0|\n",
      "|20211212|       0|      4|       9|      0|       0|\n",
      "|20211212|       0|      1|       4|      0|       0|\n",
      "|20211212|       0|      6|       2|      0|       0|\n",
      "|20211212|       0|      6|       7|      0|       0|\n",
      "|20211212|       0|      6|       3|      0|       0|\n",
      "|20211212|       0|      6|       6|      0|       0|\n",
      "|20211212|    1500|      3|       5|      0|       0|\n",
      "|20211212|    1500|      2|       0|      0|       0|\n",
      "|20211212|    1500|      5|       8|      0|       0|\n",
      "|20211212|    1500|      0|       1|      0|       0|\n",
      "|20211212|    1500|      4|       9|      0|       0|\n",
      "|20211212|    1500|      1|       4|      0|       0|\n",
      "|20211212|    1500|      6|       2|      0|       0|\n",
      "|20211212|    1500|      6|       7|      0|       0|\n",
      "|20211212|    1500|      6|       3|      0|       0|\n",
      "|20211212|    1500|      6|       6|      0|       0|\n",
      "+--------+--------+-------+--------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2652"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_quarter_hourly_data = df\n",
    "\n",
    "fact_quarter_hourly_data.show()\n",
    "fact_quarter_hourly_data.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+--------+-------+--------+\n",
      "|Date_Key|Time_Key|StoreID|SensorID|InCount|OutCount|\n",
      "+--------+--------+-------+--------+-------+--------+\n",
      "|20211212|       0|      3|       5|      0|       0|\n",
      "|20211212|       0|      2|       0|      0|       0|\n",
      "|20211212|       0|      5|       8|      0|       0|\n",
      "|20211212|       0|      0|       1|      0|       0|\n",
      "|20211212|       0|      4|       9|      0|       0|\n",
      "|20211212|       0|      1|       4|      0|       0|\n",
      "|20211212|       0|      6|       2|      0|       0|\n",
      "|20211212|       0|      6|       7|      0|       0|\n",
      "|20211212|       0|      6|       3|      0|       0|\n",
      "|20211212|       0|      6|       6|      0|       0|\n",
      "|20211212|    1500|      3|       5|      0|       0|\n",
      "|20211212|    1500|      2|       0|      0|       0|\n",
      "|20211212|    1500|      5|       8|      0|       0|\n",
      "|20211212|    1500|      0|       1|      0|       0|\n",
      "|20211212|    1500|      4|       9|      0|       0|\n",
      "|20211212|    1500|      1|       4|      0|       0|\n",
      "|20211212|    1500|      6|       2|      0|       0|\n",
      "|20211212|    1500|      6|       7|      0|       0|\n",
      "|20211212|    1500|      6|       3|      0|       0|\n",
      "|20211212|    1500|      6|       6|      0|       0|\n",
      "+--------+--------+-------+--------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "daily_data = df\n",
    "daily_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data = daily_data.groupBy(['Date_Key', 'StoreID', 'SensorID']).agg(\n",
    "    sum('InCount').alias('InCount'),\n",
    "    sum('OutCount').alias('OutCount'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+-------+--------+\n",
      "|Date_Key|StoreID|SensorID|InCount|OutCount|\n",
      "+--------+-------+--------+-------+--------+\n",
      "|20211212|      3|       5|    636|     634|\n",
      "|20211212|      6|       2|    243|     193|\n",
      "|20211213|      5|       8|    141|     133|\n",
      "|20211211|      6|       6|     60|      70|\n",
      "|20211213|      0|       1|    338|     322|\n",
      "|20211213|      6|       7|     35|      31|\n",
      "|20211211|      5|       8|    424|     419|\n",
      "|20211212|      6|       7|    216|     190|\n",
      "|20211213|      6|       6|     20|      14|\n",
      "|20211213|      1|       4|    208|     216|\n",
      "|20211211|      3|       5|    421|     416|\n",
      "|20211211|      6|       7|    156|     130|\n",
      "|20211213|      3|       5|    142|     139|\n",
      "|20211212|      5|       8|    580|     571|\n",
      "|20211212|      0|       1|   1484|    1471|\n",
      "|20211211|      0|       1|   1171|    1162|\n",
      "|20211212|      4|       9|   1201|    1199|\n",
      "|20211213|      6|       3|      5|      11|\n",
      "|20211211|      4|       9|    936|     935|\n",
      "|20211213|      2|       0|    506|     504|\n",
      "+--------+-------+--------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_data.show()\n",
    "daily_data.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session Halt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-env",
   "language": "python",
   "name": "spark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
